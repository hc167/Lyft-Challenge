{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.5.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Lambda, Flatten, Dense, Dropout, Layer, Activation, Reshape, Permute\n",
    "from keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD, Adam\n",
    "import random\n",
    "\n",
    "from helper import *\n",
    "from segnet_model import *\n",
    "\n",
    "from distutils.version import LooseVersion\n",
    "\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "segnet_basic = get_segnet_basic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer_1 (Layer)              (None, 320, 800, 3)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 322, 802, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 320, 800, 64)      1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 320, 800, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 320, 800, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 160, 400, 64)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 162, 402, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 160, 400, 128)     73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 160, 400, 128)     512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 160, 400, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 80, 200, 128)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 82, 202, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 80, 200, 256)      295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 80, 200, 256)      1024      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 80, 200, 256)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 40, 100, 256)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 42, 102, 256)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 40, 100, 512)      1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 40, 100, 512)      2048      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 40, 100, 512)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 42, 102, 512)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 40, 100, 512)      2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 40, 100, 512)      2048      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 40, 100, 512)      0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 80, 200, 512)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPaddin (None, 82, 202, 512)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 80, 200, 256)      1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 80, 200, 256)      1024      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 80, 200, 256)      0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 160, 400, 256)     0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPaddin (None, 162, 402, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 160, 400, 128)     295040    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 160, 400, 128)     512       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 160, 400, 128)     0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 320, 800, 128)     0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPaddin (None, 322, 802, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 320, 800, 64)      73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 320, 800, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 320, 800, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 320, 800, 3)       195       \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 256000, 3)         0         \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 256000, 3)         0         \n",
      "=================================================================\n",
      "Total params: 5,467,395\n",
      "Trainable params: 5,463,555\n",
      "Non-trainable params: 3,840\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "segnet_basic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#segnet_basic.summary()\n",
    "segnet_basic.compile(loss=\"categorical_crossentropy\", optimizer='adadelta', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = getDataSetName()\n",
    "shuffle(samples)\n",
    "\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.20)\n",
    "validation_samples, test_samples = train_test_split(validation_samples, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data, train_label = prep_data(test_samples)\n",
    "#validate_data, validate_label = prep_data(validation_samples)\n",
    "#test_data, test_label = prep_data(test_samples)\n",
    "#epochs = 2\n",
    "#batch_size = 10\n",
    "\n",
    "#result = segnet_basic.fit(train_data, train_label, batch_size=batch_size, \n",
    "#                          epochs=epochs, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_samples, batch_size=4)\n",
    "validation_generator = generator(validation_samples, batch_size=4)\n",
    "test_generator = generator(test_samples, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1600/1600 [==============================] - 1638s 1s/step - loss: 0.1834 - acc: 0.9309 - val_loss: 0.0990 - val_acc: 0.9633\n",
      "Epoch 2/2\n",
      "1600/1600 [==============================] - 1567s 979ms/step - loss: 0.0679 - acc: 0.9747 - val_loss: 0.0722 - val_acc: 0.9734\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe518050898>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segnet_basic.fit_generator(train_generator, steps_per_epoch= len(train_samples),\n",
    "                    validation_data=validation_generator, validation_steps=len(validation_samples), epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = segnet_basic.evaluate_generator(test_generator, len(test_samples))\n",
    "print(\"Accuracy = \", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from keras.models import model_from_json\n",
    "\n",
    "segnet_basic.save('model_with_weight.h5')\n",
    "\n",
    "segnet_basic.save_weights(\"model_weight.hdf5\")\n",
    "print(\"sava weight done..\")    \n",
    "\n",
    "json_string = segnet_basic.to_json()\n",
    "\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
